token_msg = "Tokenização é o processo de dividir texto em unidades menores (tokens), facilitando o processamento NLP."

title_msg = "NLP Playgorund"

pos_msg = "POS (Part of Speech) são categorias gramaticais que indicam a função das palavras na frase."

lem_msg = "Lemmatization é o processo de reduzir uma palavra à sua forma base ou lema, considerando o contexto gramatical."

desc_app = "App em Python e spaCy para explorar tokenização, lematização e POS em textos de forma simples."